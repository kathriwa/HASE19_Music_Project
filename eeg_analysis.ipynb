{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation and Data Loading\n",
    "\n",
    "### Defining the relevant column names and directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the filename to get participant ID, task number and programming or break condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_info(filename):\n",
    "    split_name = filename.split('_')\n",
    "    p_id = split_name[0]\n",
    "    task_no = split_name[1]\n",
    "    task = split_name[2].split('.')[0]\n",
    "\n",
    "    return p_id, task_no, task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data\n",
    "\n",
    "- Remove unnecessary columns\n",
    "- Drop empty rows\n",
    "- Filter out rows with a bad signal (hsi_precision > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_file(path_to_file, filename):\n",
    "    df = pd.read_csv(path_to_file + filename)\n",
    "    # Remove unnecessary columns and drop empty rows\n",
    "    df_clean = df[[col for col in cols]].dropna(thresh=2).reset_index(drop=True)\n",
    "    # Group every 5 rows together to one row\n",
    "    df_clean = df_clean.groupby(np.arange(len(df_clean)) // 5).agg({'timestamps':'mean',\n",
    "                                                                'theta_absolute_1':'mean',\n",
    "                                                                'theta_absolute_2':'mean',\n",
    "                                                                'theta_absolute_3':'mean',\n",
    "                                                                'theta_absolute_4':'mean',\n",
    "                                                                'alpha_absolute_1': 'mean',\n",
    "                                                                'alpha_absolute_2': 'mean',\n",
    "                                                                'alpha_absolute_3': 'mean',\n",
    "                                                                'alpha_absolute_4': 'mean',\n",
    "                                                                'beta_absolute_1': 'mean',\n",
    "                                                                'beta_absolute_2': 'mean',\n",
    "                                                                'beta_absolute_3': 'mean',\n",
    "                                                                'beta_absolute_4': 'mean',\n",
    "                                                                'blink': 'mean',\n",
    "                                                                'hsi_precision_1': 'mean',\n",
    "                                                                'hsi_precision_2': 'mean',\n",
    "                                                                'hsi_precision_3': 'mean',\n",
    "                                                                'hsi_precision_4': 'mean'\n",
    "                                                               })\n",
    "    # remove rows with bad signal\n",
    "    df_good_signal = df_clean[(df_clean.hsi_precision_1 < 3) & (df_clean.hsi_precision_2 < 3) & \n",
    "                          (df_clean.hsi_precision_3 < 3) & (df_clean.hsi_precision_4 < 3)]\n",
    "    \n",
    "    return df_good_signal[['timestamps', 'theta_absolute_1', 'theta_absolute_2', 'theta_absolute_3',\n",
    "                           'theta_absolute_4', 'alpha_absolute_1', 'alpha_absolute_2', 'alpha_absolute_3', \n",
    "                           'alpha_absolute_4', 'beta_absolute_1', 'beta_absolute_2', 'beta_absolute_3',\n",
    "                           'beta_absolute_4', 'blink']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_2nd_min(clean_df_break):\n",
    "    \n",
    "    # Find timestamps for last minute of recording\n",
    "    begin_last_min = max(clean_df_break.timestamps) - 60\n",
    "    # find index of first instance within that minute\n",
    "    begin_idx = (clean_df_break.timestamps.values >= begin_last_min).argmax()\n",
    "    # Split dataframe\n",
    "    df_min2 = clean_df_break.iloc[begin_idx:].reset_index(drop=True)\n",
    "    \n",
    "    return df_min2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_blink_per_sec(clean_df):\n",
    "    # blinkrate per sec\n",
    "    df_blink = clean_df[['timestamps', 'blink']]\n",
    "    df_blink['timestamps'] = df_blink['timestamps'].astype(int)\n",
    "    df_bps = df_blink.groupby(by=\"timestamps\").aggregate('mean')\n",
    "    \n",
    "    return df_bps\n",
    "\n",
    "def compute_blink_baseline(df_bps):\n",
    "    return np.mean(df_bps['blink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eeg_baselines(clean_df):\n",
    "    # Baseline: Mean of 2nd minute\n",
    "\n",
    "    baseline_freq_list = [clean_df.theta_absolute_1.mean(), clean_df.theta_absolute_2.mean(),\n",
    "                          clean_df.theta_absolute_3.mean(), clean_df.theta_absolute_4.mean(),\n",
    "                          clean_df.alpha_absolute_1.mean(), clean_df.alpha_absolute_2.mean(),\n",
    "                          clean_df.alpha_absolute_3.mean(), clean_df.alpha_absolute_4.mean(),\n",
    "                          clean_df.beta_absolute_1.mean(), clean_df.beta_absolute_2.mean(),\n",
    "                          clean_df.beta_absolute_3.mean(), clean_df.beta_absolute_4.mean()] \n",
    "\n",
    "    baseline_df = pd.DataFrame([baseline_freq_list], columns=[\"theta_absolute_1\", \"theta_absolute_2\",\n",
    "                                                              \"theta_absolute_3\", \"theta_absolute_4\",\n",
    "                                                              \"alpha_absolute_1\", \"alpha_absolute_2\",\n",
    "                                                              \"alpha_absolute_3\", \"alpha_absolute_4\",\n",
    "                                                              \"beta_absolute_1\", \"beta_absolute_2\",\n",
    "                                                              \"beta_absolute_3\", \"beta_absolute_4\"])\n",
    "    \n",
    "    return baseline_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_baseline(clean_df_break):\n",
    "    min2_df = filter_out_2nd_min(clean_df_break)\n",
    "    blinks = compute_blink_per_sec(min2_df)\n",
    "    blinks = compute_blink_baseline(blinks)\n",
    "    eegs = compute_eeg_baselines(min2_df)\n",
    "    return blinks, eegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_music_map(filename):\n",
    "    music_conditions = pd.read_csv(filename, sep=';')\n",
    "    music_conditions = music_conditions[['ID', 'Music 1', 'Music 2', 'Music 3', 'Music 4']]\n",
    "    return music_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_music_condition(music_file, p_id, task):\n",
    "    music_df = load_music_map(music_file)\n",
    "    music_condition = music_df.loc[music_df[\"ID\"] == p_id]\n",
    "    return int(music_condition.iloc[:, int(task)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(break_df, cleaned_df):\n",
    "    # get 1 sec averages\n",
    "    cleaned_df['timestamps'] = cleaned_df['timestamps'].astype(int)\n",
    "    grouped_df = cleaned_df.groupby(by='timestamps', as_index=False).aggregate('mean')\n",
    "    blink_base, eeg_base = compute_baseline(break_df)\n",
    "    # normalize blink\n",
    "    grouped_df['blink'] = grouped_df['blink'] - blink_base\n",
    "    # normalize eeg\n",
    "    for col in cols[1:13]:\n",
    "        grouped_df[col] = grouped_df[col] - eeg_base[col].values[0]\n",
    "    # get avg for 10 secs interval -> remove last digit and group by timestamp?\n",
    "    grouped_df['timestamps'] = grouped_df['timestamps'].astype(str).str[:-1].astype(np.int64)\n",
    "    df_10_secs = grouped_df.groupby(by='timestamps', as_index=False).aggregate('mean')\n",
    "    \n",
    "    return df_10_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tei_tdi(normalized_df):\n",
    "    # avg values of sensors and compute tdi and tei\n",
    "    theta = normalized_df[['theta_absolute_1', 'theta_absolute_2', \n",
    "                           'theta_absolute_3', 'theta_absolute_4']].mean(axis=1)\n",
    "    alpha = normalized_df[['alpha_absolute_1', 'alpha_absolute_2', \n",
    "                           'alpha_absolute_3', 'alpha_absolute_4']].mean(axis=1)\n",
    "    beta = normalized_df[['beta_absolute_1', 'beta_absolute_2', \n",
    "                          'beta_absolute_3', 'beta_absolute_4']].mean(axis=1)\n",
    "    tei = beta / (alpha + theta)\n",
    "    tdi = theta / (alpha + beta)\n",
    "    \n",
    "    return tei.values.tolist(), tdi.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_results(max_len, results):\n",
    "    padded_index = []\n",
    "    for r in results:\n",
    "        if len(r) < (max_len + 3):\n",
    "            r = r + [np.nan] * (max_len - len(r) - 3)\n",
    "        padded_index.append(r)\n",
    "    return padded_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames, IDs, Columnnames, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ids = ['P01', 'P02', 'P03', 'P04', 'P05', 'P06', 'P07', 'P08', 'P09', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15']\n",
    "task_numbers = [1, 2, 3, 4]\n",
    "music_mapping_file = 'music_lookup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/'\n",
    "\n",
    "data_files = os.listdir(directory)\n",
    "cols = ['timestamps', 'theta_absolute_1', 'theta_absolute_2', 'theta_absolute_3', 'theta_absolute_4',\n",
    "            'alpha_absolute_1', 'alpha_absolute_2', 'alpha_absolute_3', 'alpha_absolute_4',\n",
    "            'beta_absolute_1', 'beta_absolute_2', 'beta_absolute_3', 'beta_absolute_4',\n",
    "            'blink','hsi_precision_1', 'hsi_precision_2', 'hsi_precision_3', 'hsi_precision_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over the files and extracting the TEI, TDI and blink rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:\n",
      "participant P05\n",
      "programming task 2\n",
      "music condition 3\n",
      "programming\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hri/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3209: DtypeWarning: Columns (93,94,98) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading baseline file P05_2_break.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hri/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3209: DtypeWarning: Columns (93,94,95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/Users/hri/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P06\n",
      "programming task 3\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P06_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P02\n",
      "programming task 4\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P02_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P12\n",
      "programming task 1\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P12_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P03\n",
      "programming task 3\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P03_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P07\n",
      "programming task 4\n",
      "music condition 4\n",
      "programming\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hri/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3209: DtypeWarning: Columns (97,98,99) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading baseline file P07_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P04\n",
      "programming task 2\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P04_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P07\n",
      "programming task 3\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P07_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P03\n",
      "programming task 4\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P03_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P01\n",
      "programming task 2\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P01_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P02\n",
      "programming task 3\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P02_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P13\n",
      "programming task 1\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P13_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P06\n",
      "programming task 4\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P06_4_break.csv\n",
      "File P06_4_break.csv does not exist!\n",
      "loading:\n",
      "participant P07\n",
      "programming task 2\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P07_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P15\n",
      "programming task 1\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P15_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P04\n",
      "programming task 3\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P04_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P09\n",
      "programming task 1\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P09_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P02\n",
      "programming task 2\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P02_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P01\n",
      "programming task 3\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P01_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P10\n",
      "programming task 1\n",
      "music condition 1\n",
      "programming\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hri/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3209: DtypeWarning: Columns (97,98,102) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading baseline file P10_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P05\n",
      "programming task 4\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P05_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P06\n",
      "programming task 2\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P06_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P05\n",
      "programming task 3\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P05_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P14\n",
      "programming task 1\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P14_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P08\n",
      "programming task 1\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P08_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P01\n",
      "programming task 4\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P01_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P03\n",
      "programming task 2\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P03_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P11\n",
      "programming task 1\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P11_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P04\n",
      "programming task 4\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P04_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P09\n",
      "programming task 3\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P09_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P11\n",
      "programming task 4\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P11_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P15\n",
      "programming task 3\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P15_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P04\n",
      "programming task 1\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P04_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P14\n",
      "programming task 4\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P14_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P13\n",
      "programming task 2\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P13_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P01\n",
      "programming task 1\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P01_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P10\n",
      "programming task 3\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P10_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P08\n",
      "programming task 4\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P08_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P08\n",
      "programming task 3\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P08_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P10\n",
      "programming task 4\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P10_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P05\n",
      "programming task 1\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P05_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P14\n",
      "programming task 3\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P14_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P15\n",
      "programming task 4\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P15_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P12\n",
      "programming task 2\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P12_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P11\n",
      "programming task 3\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P11_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P09\n",
      "programming task 4\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P09_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P13\n",
      "programming task 4\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P13_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P08\n",
      "programming task 2\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P08_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P14\n",
      "programming task 2\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P14_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P06\n",
      "programming task 1\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P06_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P11\n",
      "programming task 2\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P11_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P12\n",
      "programming task 3\n",
      "music condition 1\n",
      "programming\n",
      "\n",
      "loading baseline file P12_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P03\n",
      "programming task 1\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P03_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P12\n",
      "programming task 4\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P12_4_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P09\n",
      "programming task 2\n",
      "music condition 4\n",
      "programming\n",
      "\n",
      "loading baseline file P09_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P15\n",
      "programming task 2\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P15_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P07\n",
      "programming task 1\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P07_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P10\n",
      "programming task 2\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P10_2_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P02\n",
      "programming task 1\n",
      "music condition 3\n",
      "programming\n",
      "\n",
      "loading baseline file P02_1_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n",
      "loading:\n",
      "participant P13\n",
      "programming task 3\n",
      "music condition 2\n",
      "programming\n",
      "\n",
      "loading baseline file P13_3_break.csv\n",
      "normalizing the data\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tei_results = []\n",
    "tdi_results = []\n",
    "blink_results = []\n",
    "max_tei_len = 0\n",
    "min_tei_len = 999\n",
    "for f in data_files:\n",
    "    if f.startswith('P'):\n",
    "        p_id, task, condition = extract_file_info(f)\n",
    "        music_condition = extract_music_condition(music_mapping_file, p_id, task)\n",
    "        if condition == 'programming':\n",
    "            result_prefix = [p_id, task, music_condition]\n",
    "            print('loading:')\n",
    "            print('participant', p_id)\n",
    "            print('programming task', task)\n",
    "            print('music condition', music_condition)\n",
    "            print(condition)\n",
    "            print()\n",
    "            cleaned_data = load_and_clean_file(directory, f)\n",
    "            base_file = p_id + '_' + task + '_break.csv'\n",
    "            print('loading baseline file', base_file)\n",
    "            try:\n",
    "                baseline_df = load_and_clean_file(directory, base_file)\n",
    "            except FileNotFoundError:\n",
    "                print(\"File \" + base_file + \" does not exist!\")\n",
    "                continue\n",
    "            print('normalizing the data')\n",
    "            print()\n",
    "            print()\n",
    "            normalized_df = normalize_data(baseline_df, cleaned_data)\n",
    "            blink_rates = normalized_df['blink'].values.tolist()\n",
    "            tei, tdi = compute_tei_tdi(normalized_df)\n",
    "            if len(tei) > max_tei_len:\n",
    "                max_tei_len = len(tei)\n",
    "            if len(tei) < min_tei_len:\n",
    "                min_tei_len = len(tei)\n",
    "            blink_results.append(result_prefix + blink_rates)\n",
    "            tei_results.append(result_prefix + tei)\n",
    "            tdi_results.append(result_prefix + tdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tei = pad_results(max_tei_len, tei_results)\n",
    "padded_tdi = pad_results(max_tei_len, tdi_results)\n",
    "padded_blinks = pad_results(max_tei_len, blink_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = ['p_id', 'programming_task', 'music_cond'] + ['intervall_' + str(i) for i in range(max_tei_len)]\n",
    "tei_df = pd.DataFrame(padded_tei, columns=df_cols)\n",
    "tdi_df = pd.DataFrame(padded_tdi, columns=df_cols)\n",
    "blink_df = pd.DataFrame(padded_blinks, columns=df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "blink_df.to_csv('blink_results.csv', index=None)\n",
    "tdi_df.to_csv('tdi_results.csv', index=None)\n",
    "tei_df.to_csv('tei_results.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Renaming of files after download from SwitchDrive\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import rename, rmdir\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Works with Luka's naming scheme\n",
    "def unzip():\n",
    "    for filename in Path('data').rglob('*.zip'):\n",
    "        parts = filename.parts\n",
    "        with ZipFile(filename, 'r') as zipObj:\n",
    "            zipObj.extractall('tmp')\n",
    "        name = parts[-1]\n",
    "        if re.search(r'.*break.*',name):\n",
    "            name = re.sub(r'([0-9]).*dition ([0-9]).*(ID[0-9][0-9]?)\\.zip', r'break\\1_condition\\2_\\3.csv',name)\n",
    "        else:\n",
    "            name = re.sub(r'([0-9]).*dition ([0-9]).*(ID[0-9][0-9]?)\\.zip', r'programming\\1_condition\\2_\\3.csv',name)\n",
    "\n",
    "        for museFile in Path('tmp').rglob('*'):\n",
    "            p = museFile.parts\n",
    "            rename(museFile,'data/' + name)\n",
    "    rmdir('tmp')\n",
    "    \n",
    "\n",
    "# Replaces the 'XxX' placeholder with condition number e.g. focus music = 1, office = 4 ...\n",
    "def addConditions(filename, participant_id):\n",
    "    conditionOrder = re.search(r'.*([0-9])_.*',filename)\n",
    "    conditionOrder = int(conditionOrder.group(1))\n",
    "    order = getMusicOrderList()[int(participant_id) - 1] # -1 ==> the ordering of lists starts with 0\n",
    "    return re.sub(r'XxX',str(order[conditionOrder - 1]),filename)\n",
    "    \n",
    "    \n",
    "\n",
    "# Normalizing the naming scheme of files from Kathrin\n",
    "def renameKathrin():\n",
    "    for filename in Path('data').rglob('*.csv'):\n",
    "        name = filename.parts[-1]\n",
    "        if re.search(r'P.*',name):\n",
    "            name = re.sub(r'^P([0-9]{2})_([0-9])_(.*)\\.csv$', r'\\3\\2_conditionXxX_ID\\1.csv',name)\n",
    "            rename(filename,'data/'+name)\n",
    "            \n",
    "            # Normalize the ID numbering\n",
    "            participant_id = re.search(r'.*ID([0-9][0-9]?)',name)\n",
    "            participant_id = participant_id.group(1)\n",
    "            participant_id = int(participant_id)            \n",
    "            participant_id = str(participant_id)\n",
    "            newName = re.sub(r'ID[0-9]{2}',\"ID\"+participant_id,name)\n",
    "            \n",
    "            newName = addConditions(newName, participant_id) # adds condition into the naming scheme\n",
    "            rename('data/'+name,'data/' + newName)\n",
    "            \n",
    "    \n",
    "            \n",
    "# P08_1_break.csv\n",
    "            \n",
    "            \n",
    "def getMusicOrderList():\n",
    "    musicOrderList = []\n",
    "    musicOrder_df = pd.read_csv('music_lookup.csv',sep=';')\n",
    "    musicOrder_df.dropna(axis=0, thresh=3, inplace=True) # Tresh = 3 ==> rows/cols have 2 NA\n",
    "    musicOrder_df.dropna(axis=1, thresh=3, inplace=True)\n",
    "\n",
    "    for i in range(musicOrder_df.shape[0]):\n",
    "        row = musicOrder_df.iloc[i]\n",
    "        row = list(row)\n",
    "        musicOrderList.append([int(condition_num) for condition_num in row[1:5]]) # '1:5' because we have 4 conditions\n",
    "    return musicOrderList\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
